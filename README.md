System design for analyzing selected emotional states of people based on the recorded facial image.
The work included the development of a proprietary image dataset, which was characterized by clear registration of facial areas. During the realization of the dataset, 
the focus was on correct emotion labeling and ensuring the equality of the in the representativeness of each class. 
This was followed by an analysis of the acquisition methods and processing of facial images. 
Significantly different feature extraction methods were discussed. By rejecting one of them and choosing an alternative route for feature extraction and classification, 
it was possible to create a system that works correctly for data taken from the camera in real time (20 FPS while face was detected).
